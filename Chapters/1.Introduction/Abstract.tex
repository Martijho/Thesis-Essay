\begin{abstract}
How is it that the human brain is capable of learning a seemingly endless amount of tasks? Could we construct our artificial minds to do the same? As machine learning becomes increasingly better at problem-solving, the logical step is to push the progress towards building systems capable of solving multiple tasks to a satisfactory level. 

In 2017, Google DeepMind presented their modular Deep Learning structure, PathNet, a structure capable of retaining solutions in parameter space to multiple problems at the same time, as well as providing the possibility of reusing segments of existing solutions to solve future problems. 

This thesis continues that work by exploring how the reuse of knowledge between problems can be improved. Three experiments are conducted. The first of which, a comparison between modular PathNet training and a classical Machine Learning approach,  shows knowledge is significantly more transferable when parameters are optimized in a modular training context.

The second and third experiments investigate the genetic algorithm initially used for optimizing the selection of parameters. By tweaking the algorithms ability to explore possibilities, seven different search schemes are tested on a set of six classification problems, all within the image domains of handwritten digits and images of house numbers. While unable to show these algorithms affecting knowledge reuse differently, the experiments provide insight into the effect such algorithms have on the produced solutions.  
\end{abstract}

\iffalse
    What is all this about? 
    Why should I read this thesis? 
    Is it any good? 
    What's new? 
\fi
