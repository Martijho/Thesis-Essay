\chapter{Experiment 3: Relearning a task}
\label{exp3}
The motivation behind reusing modules is as mentioned in the introduction, to increase the number of tasks a PathNet can learn before being saturated by decreasing the amount of new capacity a path needs for a new task. A optimal search algorithm for new paths should therefore be able to reuse as much knowledge as possible without limiting the performance. If we assume a ideal search algorithm would find optimal modules for each task, it should be able to find and reuse all learned knowledge if a task is learned twice. 

We can put this to the test by learning some task twice for all seven algorithms in chapter \ref{exp2}. As the amount of module reuse in these experiments were small, we lower the proverbial bar here by reducing the module search space.

The question we want to answer is this: \textit{"Given optimal conditions for module reuse\footnote{By optimal conditions we mean learning a task where a full set of parameters is already optimized for that task.}, which selection pressure scheme is best suited for knowledge reuse?"}

\section{Description}
The experimental structure here is simple. The same experimental parameters as the experiment in chapter \ref{exp2} are used again, but here the the seven algorithms will here be applied to a binary task problem where both tasks are the same: a cSVHN classification problem with all 10 classes. After searching for a optimal path for both tasks, the reuse is noted. 

By performing this experimental trial for each algorithm multiple times, we can compare the observations of reuse with the probability of seeing these results in random module selection, and then with each other. 

\section{Hypothesis}
Based on the reuse in the previous selection pressure experiments, we do not expect any algorithm to yield perfect results\footnote{Perfect results here would constitute finding all modules used in the previous path}, but instead have a statistically significant difference from random module selection. Given the algorithms different selection pressures, they are expected to give somewhat different reuse results.

As each search should be capable of reaching a decent validation accuracy on its own, it is not expected that there will be a significant difference between task 1 and task 2 for any of the algorithms. However, there is no reason to believe the effects the different tournament sizes have on accuracy will be any different than in chapter \ref{exp2}. 

\section{Experimental setup}
The experiment structure here is a binary task problem, where we want to find two paths for a full cSVHN classification problem twice, meaning both task 1 and task 2 is cSVHN classification with all classes. The two searches should have a non-zero probability of zero reuse, so the PathNet dimensions are set to 3 layers of 6 modules each with a maximum of 3 active modules pr. paths layer. We can describe the total number of possible paths as 
\begin{equation*}
    \prod_{i=0}^{\omega-1}(M-i)^{L}
\end{equation*}
where \(\omega\) is the maximum number of active modules in each layer for each path, \(M\) is the number of modules in each PathNet layer and  \(L\) is the number of layers in the PathNet. This means the number of possible paths in a 20-by-3 PathNet with \(\omega=3\) is  
\begin{equation*}
    \prod_{i=0}^{3-1}(20-i)^{3}\approx 3.2\times10^{11}
\end{equation*}
and in this experiment
\begin{equation*}
    \prod_{i=0}^{3-1}(6-i)^{3}\approx 1.7\times10^{6}
\end{equation*}
Reducing the PathNet size from 20 modules in each layer to 6 have reduced the search space with 5 orders of magnitude, and it should therefore be significantly easier to find reusable modules here than in the previous experiment.

\input{Chapters/4.Experiments/exp3/tables/motecarlo.tex}

We can approximate the probability of finding any number of reuse by randomly selecting two paths within the limitations of the PathNet dimensions and path-size with a Monte-Carlo approach. Using equation \ref{eq:montecarloP} where we want the probabilities to be minimum 10 times as large as the standard deviation (\(R=0.1\)) and \(n=10^{9}\) Monte-Carlo trials, we calculate the probability accuracy to be 
\begin{equation*}
    \frac{1}{nR^{2}+1}=\frac{1}{10^{7}+1}\approx10^{-7}
\end{equation*}
Meaning we can tell the probability of reuse to the seventh decimal place from the Monte-Carlo results. The results of the performed Monte-Carlo estimation can be found in table \ref{tab:montecarlo}.

We will calculate the expected reuse distribution based on the Monte-Carlo estimated probabilities, and use Mann-Whitney tests to see how the algorithms reuse holds up compared to expectations. 

Learning from the conclusion in chapter \ref{exp2}, the algorithms maximum tournament size is reduced from 25 to 10.

\section{Results}
\subsection{Population Diversity}
\begin{figure}[h!]
    \includegraphics[width=\textwidth, center]{Chapters/4.Experiments/exp3/figures/diversity_hamming.pdf}
    \caption[Hamming diversity plot]{The average pair-wise Hamming distance diversity for each algorithm over 250 generations.}
    \label{fig:exp3.hamming}
\end{figure}
\begin{figure}[h!]
    \includegraphics[width=\textwidth, center]{Chapters/4.Experiments/exp3/figures/diversity_frequency.pdf}
    \caption[Frequency diversity plot]{The average amount of unique paths for each algorithm over 250 generations.}
    \label{fig:exp3.frequency}
\end{figure}

As the algorithms run here are the same as in chapter \ref{exp2}, the convergence rates are quite similar to figures \ref{fig:exp3.hamming} and \ref{fig:exp3:frequency}. However, the searches are run for 250 generations, which makes the diversity drop in algorithms with slow convergence, such as 1a and 1c, become apparent. 

Noteworthy about these diversity plots is that algorithm 1c in both cases converge more within the 250 generations for task 2 than task 1. Testing the null-hypothesis that the final generations population have a similar pair-wise Hamming distance for task 1 than task 2 gives a p-value of 0.00229 for a one-sided Mann-Whitney test. Confirming the observation is not due to a outlier in the data, but rather a difference in the diversity distributions. 

\subsection{Modular reuse}
\begin{sidewaysfigure}[p!]
    \includegraphics[width=1.2\textwidth, center]{Chapters/4.Experiments/exp3/figures/reuse_progression.pdf}
    \caption[Module reuse during search]{The change in reuse plotted over the search duration. Four generation limits were used, but the reuse during search are expected to be the same across the different search termination limits.}
    \label{fig:exp3.reuseprogression}
\end{sidewaysfigure}
\begin{figure}[h]
    \includegraphics[width=1.25\textwidth, center]{Chapters/4.Experiments/exp3/figures/reuse_boxplot.pdf}
    \caption[Module reuse boxplot]{The average amount of unique paths for each algorithm over 250 generations.}
    \label{fig:exp3.reuseboxplot}
\end{figure}

Figure \ref{fig:exp3.reuseprogression} show the average reuse for each algorithm changing during the searches with different termination limit. Algorithms with high reuse for the second task (1b and 2b) reach the highest level of reuse within the first 30 generations, whereupon it start to drop. Algorithms using a low tournament size instead gradually increase in reuse, where it looks to surpass the other algorithms around 100 generations.  

The box-plot in figure \ref{fig:exp3.reuseboxplot} show the reuse in the optimal paths selected for task 2. The searches are stopped at different points, but there does not look to be any striking differences in any of the groups of reuse. They do all, however, seem to score higher than the expected reuse from random modules selection. 
\subsection{Path fitness}
\begin{sidewaysfigure}[h]
    \includegraphics[width=1.25\textwidth, center]{Chapters/4.Experiments/exp3/figures/fitness_progression.pdf}
    \caption[Changes in average tournament fitness]{The average tournament fitness for each generation. The dotted lines are average fitness during search for task 1, while the whole lines are for task 2.}
    \label{fig:exp3.fitness}
\end{sidewaysfigure}

Figure \ref{fig:exp3.fitness} show the average tournament fitness for each generation. As with results in chapter \ref{exp2}, the algorithms with high tournament size plateau in fitness quicker than algorithms with a low tournament size.

Noteworthy features of this plot is the increase in average fitness for algorithms with low tournament size in the start of each search from task 1 to task 2, suggesting the learning is easier the second time around. 

\section{Discussion}
\section{Conclusion}
